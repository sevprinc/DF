{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_model = 'EfficientNetAutoAttB4ST'\n",
    "train_db = 'DFDC'\n",
    "\n",
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "face_policy = 'scale'\n",
    "face_size = 224\n",
    "frames_per_video = 128\n",
    "\n",
    "facedet = BlazeFace().to(device)\n",
    "facedet.load_weights(\"../blazeface/blazeface.pth\")\n",
    "facedet.load_anchors(\"../blazeface/anchors.npy\")\n",
    "videoreader = VideoReader(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save features\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model_url = weights.weight_url['{:s}_{:s}'.format(net_model,train_db)]\n",
    "net = getattr(fornet,net_model)().eval().to(device)\n",
    "net.load_state_dict(load_url(model_url,map_location=device,check_hash=True))\n",
    "transf = utils.get_transformer(face_policy, face_size, net.get_normalizer(), train=False)\n",
    "names = ['CH','BO', 'RF', 'KP', 'EC', 'TB', 'JP', 'LN', 'MS', 'ND'] \n",
    "\n",
    "for name in names:\n",
    "    for idx in range(5):      \n",
    "        recon_path = './reconstructed_videos/'\n",
    "        real_videos_train, real_videos_valid, real_videos_test = [], [], []\n",
    "        fake_videos_train, fake_videos_valid, fake_videos_test = [], [], []\n",
    "        mypath = './celeb_videos/' + name + '/'\n",
    "        video_files = []\n",
    "        for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "            video_files.extend(filenames)\n",
    "            break\n",
    "        i = idx\n",
    "        \n",
    "        capture = cv2.VideoCapture(mypath + video_files[i])\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        video_read_fn = lambda x: videoreader.read_frames(x, frame_count, jitter=0, seed=None)\n",
    "        face_extractor = FaceExtractor(video_read_fn=video_read_fn,facedet=facedet)\n",
    "        vid_real_faces = face_extractor.process_video(mypath + video_files[i])\n",
    "        faces_real_t = torch.stack( [ transf(image=frame['faces'][0])['image'] for frame in vid_real_faces if len(frame['faces'])] )\n",
    "\n",
    "        vid_name = video_files[i][0:3] + 'FSG_all_recon1.mp4'\n",
    "        vid_faces = face_extractor.process_video(recon_path + vid_name)\n",
    "        faces_real_recon = torch.stack( [ transf(image=frame['faces'][0])['image'] for frame in vid_faces if len(frame['faces'])] )\n",
    "        with torch.no_grad():\n",
    "            out1 = net.features(faces_real_t.to(device))\n",
    "            out2 = net.features(faces_real_recon.to(device))\n",
    "        with open('./saved_features/features_real_'+name+'_v_'+str(idx)+'_recon_all_fpv'+str(frames_per_video)+'.pkl', 'wb') as f: pickle.dump([out1, out2], f) #save results\n",
    "            \n",
    "            \n",
    "        mypath = './celeb_videos/fake_' + name + '/'\n",
    "        video_files = []\n",
    "        for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "            video_files.extend(filenames)\n",
    "            break\n",
    "        i = idx\n",
    "        capture = cv2.VideoCapture(mypath + video_files[i])\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        video_read_fn = lambda x: videoreader.read_frames(x, frame_count, jitter=0, seed=None)\n",
    "        face_extractor = FaceExtractor(video_read_fn=video_read_fn,facedet=facedet)\n",
    "        vid_fake_faces = face_extractor.process_video(mypath + video_files[i])\n",
    "        faces_fake_t = torch.stack( [ transf(image=frame['faces'][0])['image'] for frame in vid_fake_faces if len(frame['faces'])] )\n",
    "        \n",
    "        vid_name = video_files[i]\n",
    "        vid_name = vid_name[:vid_name.index(\".\")]\n",
    "        vid_name = vid_name + 'FSG_all_recon1.mp4'\n",
    "        vid_fake_faces = face_extractor.process_video(recon_path + vid_name)\n",
    "        faces_fake_recon = torch.stack( [ transf(image=frame['faces'][0])['image'] for frame in vid_fake_faces if len(frame['faces'])] )\n",
    "        with torch.no_grad():\n",
    "            out1 = net.features(faces_fake_t.to(device))\n",
    "            out2 = net.features(faces_fake_recon.to(device))\n",
    "        with open('./saved_features/features_fake_'+name+'_v_'+str(idx)+'_recon_all_fpv'+str(frames_per_video)+'.pkl', 'wb') as f: pickle.dump([out1, out2], f) #save results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
